{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30610b65-0ca2-42c9-a1e8-2acb7ed4d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import ERFutils\n",
    "import dask\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cftime\n",
    "import dask\n",
    "import xarrayutils\n",
    "import cartopy.crs as ccrs\n",
    "from xmip.preprocessing import combined_preprocessing\n",
    "from xmip.preprocessing import replace_x_y_nominal_lat_lon\n",
    "from xmip.drift_removal import replace_time\n",
    "from xmip.postprocessing import concat_experiments\n",
    "import xmip.drift_removal as xm_dr\n",
    "import xmip as xm\n",
    "import xesmf as xe\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import cf_xarray as cfxr\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import cmocean\n",
    "import cmocean.cm as cmo\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import copy\n",
    "import os\n",
    "\n",
    "dask.config.set(**{'array.slicing.split_large_chunks': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d26f69-c55c-4690-ac48-5a27b52ea380",
   "metadata": {},
   "source": [
    "# Load data and diagnose patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e569614-2c7e-4873-93ef-a1c9a85b4746",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_set = ERFutils.model_set\n",
    "A = ERFutils.A\n",
    "ds_out = ERFutils.ds_out\n",
    "\n",
    "plot = True\n",
    "save = False\n",
    "\n",
    "output_path = ERFutils.path_to_ERF_outputs\n",
    "\n",
    "train_id = ['ssp585']\n",
    "for train in train_id:\n",
    "    print(f'Loading {train} data.')\n",
    "    pattern = {}\n",
    "    tas_CMIP_path = f'{output_path}tas/tas_CMIP_{train}_all_ds.nc4'\n",
    "    temp_response = xr.open_dataset(tas_CMIP_path) \n",
    "    for m in model_set:\n",
    "        print(f'\\t Creating pattern for {m}.')\n",
    "        \n",
    "        if 'ssp' in train:\n",
    "            global_temp = temp_response.sel(s = range(165,250)).sel(model = m).weighted(A).mean(dim = ['lat','lon']).tas.values\n",
    "            stacked_response = temp_response.sel(s = range(165,250)).sel(model = m).stack(allpoints=['lat','lon'])\n",
    "        else:\n",
    "            global_temp = temp_response.sel(model = m).weighted(A).mean(dim = ['lat','lon']).tas.values\n",
    "            stacked_response = temp_response.sel(model = m).stack(allpoints=['lat','lon'])\n",
    "\n",
    "        # Have to create the patterns locally, stack data array\n",
    "        N_latlong = len(stacked_response['allpoints'].values)\n",
    "\n",
    "        # Convert to np arrays, xarray indexing is too slow\n",
    "        pattern_stacked = np.zeros((1,N_latlong))\n",
    "        stacked_response_np = stacked_response.tas.values\n",
    "\n",
    "        # Solve for spatially resolved pattern\n",
    "        for i in range(N_latlong):\n",
    "            stacked_response_local = stacked_response_np[:,i]\n",
    "            reg = LinearRegression(fit_intercept=False).fit(global_temp.reshape(-1,1), stacked_response_local.reshape(-1,1))\n",
    "            pattern_stacked[0,i] = reg.coef_\n",
    "\n",
    "        pattern[m] = xr.Dataset(coords={'lon': ('lon', temp_response.lon.values),\n",
    "                            'lat': ('lat', temp_response.lat.values)})\n",
    "        pattern[m] = pattern[m].stack(allpoints=['lat','lon'])\n",
    "        pattern[m]['pattern'] = ('allpoints',pattern_stacked[0])\n",
    "        pattern[m] = pattern[m].unstack('allpoints')\n",
    "\n",
    "    pattern_ds = ERFutils.concat_multirun(pattern, 'model')\n",
    "    \n",
    "    #if plot:\n",
    "        #ERFutils.plot_pattern(pattern_ds, save_fig = False)\n",
    "\n",
    "    if save:\n",
    "        pattern_ds.to_netcdf(f'{output_path}pattern2_{train}_all_ds.nc4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d68c18-aede-4b84-9d07-797a0660cac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_set = ERFutils.model_set\n",
    "A = ERFutils.A\n",
    "ds_out = ERFutils.ds_out\n",
    "\n",
    "plot = True\n",
    "save = False\n",
    "\n",
    "output_path = ERFutils.path_to_ERF_outputs\n",
    "\n",
    "train_id = ['ssp126','ssp245','ssp370','ssp585']\n",
    "for train in train_id:\n",
    "    print(f'Loading {train} data.')\n",
    "    tas_CMIP_path = f'{output_path}tas/tas_CMIP_{train}_all_ds.nc4'\n",
    "    temp_response = xr.open_dataset(tas_CMIP_path) \n",
    "    \n",
    "    if 'ssp' in train:\n",
    "        global_temp = temp_response.sel(s = range(165,250)).mean(dim = 'model').weighted(A).mean(dim = ['lat','lon']).tas.values\n",
    "        stacked_response = temp_response.sel(s = range(165,250)).mean(dim = 'model').stack(allpoints=['lat','lon'])\n",
    "    else:\n",
    "        global_temp = temp_response.mean(dim = 'model').weighted(A).mean(dim = ['lat','lon']).tas.values\n",
    "        stacked_response = temp_response.mean(dim = 'model').stack(allpoints=['lat','lon'])\n",
    "\n",
    "    # Have to create the patterns locally, stack data array\n",
    "    N_latlong = len(stacked_response['allpoints'].values)\n",
    "\n",
    "    # Convert to np arrays, xarray indexing is too slow\n",
    "    pattern_stacked = np.zeros((1,N_latlong))\n",
    "    stacked_response_np = stacked_response.tas.values\n",
    "\n",
    "    # Solve for spatially resolved pattern\n",
    "    for i in range(N_latlong):\n",
    "        stacked_response_local = stacked_response_np[:,i]\n",
    "        reg = LinearRegression(fit_intercept=False).fit(global_temp.reshape(-1,1), stacked_response_local.reshape(-1,1))\n",
    "        pattern_stacked[0,i] = reg.coef_\n",
    "\n",
    "    pattern = xr.Dataset(coords={'lon': ('lon', temp_response.lon.values),\n",
    "                        'lat': ('lat', temp_response.lat.values)})\n",
    "    pattern = pattern.stack(allpoints=['lat','lon'])\n",
    "    pattern['pattern'] = ('allpoints',pattern_stacked[0])\n",
    "    pattern = pattern.unstack('allpoints')\n",
    "    \n",
    "    if plot:\n",
    "        ERFutils.plot_pattern(pattern, 'check','test',save_fig = False)\n",
    "\n",
    "    if save:\n",
    "        pattern.to_netcdf(f'{output_path}pattern2_{train}_all_ds.nc4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb44d4c-c4bb-4508-81f7-800cef6ded9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gchp",
   "language": "python",
   "name": "gchp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
