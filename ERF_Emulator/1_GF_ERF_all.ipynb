{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30610b65-0ca2-42c9-a1e8-2acb7ed4d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import ERFutils\n",
    "import dask\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cftime\n",
    "import dask\n",
    "import xarrayutils\n",
    "import cartopy.crs as ccrs\n",
    "from xmip.preprocessing import combined_preprocessing\n",
    "from xmip.preprocessing import replace_x_y_nominal_lat_lon\n",
    "from xmip.drift_removal import replace_time\n",
    "from xmip.postprocessing import concat_experiments\n",
    "import xmip.drift_removal as xm_dr\n",
    "import xmip as xm\n",
    "import xesmf as xe\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import cf_xarray as cfxr\n",
    "import scipy.signal as signal\n",
    "from scipy.sparse import diags\n",
    "from scipy.sparse.linalg import spsolve_triangular\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import cmocean\n",
    "import cmocean.cm as cmo\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "import copy\n",
    "import os\n",
    "\n",
    "dask.config.set(**{'array.slicing.split_large_chunks': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d26f69-c55c-4690-ac48-5a27b52ea380",
   "metadata": {},
   "source": [
    "# Load data and diagnose Green's Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf6c2e0-52d6-4d5d-aaa1-9761815e9250",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_set = ERFutils.model_set\n",
    "A = ERFutils.A\n",
    "ds_out = ERFutils.ds_out\n",
    "\n",
    "plot = True\n",
    "savgol = True\n",
    "save = False\n",
    "\n",
    "train_id = ['1pctCO2']\n",
    "output_path = ERFutils.path_to_ERF_outputs\n",
    "\n",
    "for train in train_id:\n",
    "    # Load ERF data\n",
    "    ERF = {}\n",
    "    ERF_path = f'{output_path}ERF/ERF_{train}_smooth_all_ds.nc4'\n",
    "    ERF_ds = xr.open_dataset(ERF_path)\n",
    "    ERF[train] = ERFutils.ds_to_dict(ERF_ds)\n",
    "    \n",
    "    # Diagnose Green's Functions\n",
    "    ds_control, ds_exp, G_ds = ERFutils.create_multimodel_GF_set(ERF, train, model_set, savgol)\n",
    "    \n",
    "    # Plot Global Mean Green's Functions (Optional)\n",
    "    if plot:\n",
    "        ERFutils.plot_mean_Greens(G_ds, train, overlay = True, save_fig = False)\n",
    "        \n",
    "    G_ds2 = G_ds.mean(dim = 'model')\n",
    "    \n",
    "    # Save Green's Functions\n",
    "    if save:\n",
    "        G_ds.to_netcdf(f'../Outputs/RF_Outputs/G_{train}_ERF_all_ds.nc4')\n",
    "        G_ds2.to_netcdf(f'../Outputs/RF_Outputs/G_{train}_ERF_mean_ds.nc4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca4f24a-5c04-4298-9f61-b26cd54b3f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_set = ERFutils.model_set\n",
    "A = ERFutils.A\n",
    "ds_out = ERFutils.ds_out\n",
    "\n",
    "train_id = ['1pctCO2']\n",
    "\n",
    "for train in train_id:\n",
    "    # Load ERF data\n",
    "    ERF = {}\n",
    "    ERF_path = f'../Outputs/RF_Outputs/ERF/ERF_{train}_all_ds.nc4'\n",
    "    ERF_ds = xr.open_dataset(ERF_path)\n",
    "    ERF[train] = ERFutils.ds_to_dict(ERF_ds)\n",
    "    \n",
    "    tas_path = f'../Outputs/RF_Outputs/tas/tas_CMIP_{train}_all_ds.nc4'\n",
    "    tas_ds = xr.open_dataset(tas_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a8d226-ece6-41cb-a97b-c79ce0669e15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "for m in model_set:\n",
    "    ax.plot(ERF[train][m].ERF.values,alpha=0.5,c='gray')\n",
    "ax.plot(ERFutils.concat_multirun(ERF[train],'model').mean(dim = 'model').ERF.values,c = 'k', linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088a6049-19f4-488d-a19a-0f6f289036f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to perform locally weighted linear regression\n",
    "def local_weighted_regression(x0, X, Y, tau):\n",
    "    # add bias term\n",
    "    x0 = np.r_[1, x0]\n",
    "    X = np.c_[np.ones(len(X)), X]\n",
    "     \n",
    "    # fit model: normal equations with kernel\n",
    "    xw = X.T * weights_calculate(x0, X, tau)\n",
    "    theta = np.linalg.pinv(xw @ X) @ xw @ Y\n",
    "    # \"@\" is used to\n",
    "    # predict value\n",
    "    return x0 @ theta\n",
    "\n",
    "def weights_calculate(x0, X, tau):\n",
    "    return np.exp(np.sum((X - x0) ** 2, axis=1) / (-2 * (tau **2) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4190a2a8-b1f2-49b6-b3db-f75b89096ab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_id = ['1pctCO2']\n",
    "from numpy import linalg as LA\n",
    "\n",
    "for train in train_id:\n",
    "    # Load ERF data\n",
    "    ERF = {}\n",
    "    ERF_path = f'../Outputs/RF_Outputs/ERF/ERF_{train}_all_ds.nc4'\n",
    "    ERF_ds = xr.open_dataset(ERF_path)\n",
    "    ERF[train] = ERFutils.ds_to_dict(ERF_ds)\n",
    "    \n",
    "    tas_path = f'../Outputs/RF_Outputs/tas/tas_CMIP_{train}_all_ds.nc4'\n",
    "    tas_ds = xr.open_dataset(tas_path)\n",
    "    \n",
    "ERF_all = ERFutils.concat_multirun(ERF[train],'model').mean(dim = 'model')\n",
    "tas_glob_mean = tas_ds.weighted(A).mean(dim = ['lat','lon']).mean(dim = ['model'])\n",
    "tas_glob_mean = tas_glob_mean.rename({'s': 'year'})\n",
    "tas_glob_mean = tas_glob_mean.sel(year = slice(ERF_all['year'].min(), ERF_all['year'].max()))\n",
    "\n",
    "domain = np.linspace(ERF_all.year.values[0], ERF_all.year.values[-1], num=len(ERF_all.year.values))\n",
    "X1 = ERF_all.year.values\n",
    "Y1 = ERF_all.ERF.values\n",
    "\n",
    "X2 = tas_glob_mean.year.values\n",
    "Y2 = tas_glob_mean.tas.values\n",
    "\n",
    "N_years = len(ERF_all['year'])\n",
    "offsets = [i for i in range(0,-N_years,-1)]\n",
    "\n",
    "for tau in [9,10,11]:\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    for i in range(2,9):\n",
    "        ERF_pred = [local_weighted_regression(x0, X1, Y1, tau) for x0 in domain]\n",
    "        tas_pred = [local_weighted_regression(x0, X2, Y2, tau) for x0 in domain]\n",
    "        input_matrix = diags(ERF_pred + ERF_pred[i],offsets=offsets,shape=(N_years,N_years),format='csr')\n",
    "        array_mat = input_matrix.toarray()\n",
    "        cond_num = LA.cond(array_mat)\n",
    "        \n",
    "        #print(f'ERF[i] = {ERF_pred[i]}, tas[i] = {tas_pred[i]}')\n",
    "        #print(f'i = {i}, Condition Number: {cond_num}')\n",
    "        \n",
    "        G = spsolve_triangular(input_matrix,tas_pred + tas_pred[i],lower=True)\n",
    "        ax.plot(G,label = f'i = {i}')\n",
    "        print(np.trapz(G))\n",
    "    \n",
    "    ax.set_title(f'tau = {tau}')\n",
    "    ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd55a2-0520-4730-94cb-79dbd3e2c09e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_id = ['1pctCO2']#,'ssp245','ssp370','ssp585','1pctCO2']\n",
    "from numpy import linalg as LA\n",
    "from scipy.linalg import solve\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "A = ERFutils.A\n",
    "\n",
    "for train in train_id:\n",
    "    # Load ERF data\n",
    "    ERF = {}\n",
    "    ERF_path = f'../Outputs/RF_Outputs/ERF/ERF_{train}_all_ds.nc4'\n",
    "    \n",
    "    #ERF_path_hist = f'../Outputs/RF_Outputs/ERF/ERF_historical_all_ds.nc4'\n",
    "    #ERF_ssp = xr.open_dataset(ERF_path)\n",
    "    #ERF_hist = xr.open_dataset(ERF_path_hist)\n",
    "\n",
    "    #ERF_ds = xr.concat([ERF_hist,ERF_ssp.assign_coords(year = range(165,250))],dim = 'year')\n",
    "    \n",
    "    ERF_ds = xr.open_dataset(ERF_path)\n",
    "    ERF[train] = ERFutils.ds_to_dict(ERF_ds)\n",
    "    \n",
    "    tas_path = f'../Outputs/RF_Outputs/tas/tas_CMIP_{train}_all_ds.nc4'\n",
    "    tas_ds = xr.open_dataset(tas_path)\n",
    "    \n",
    "    ERF_all = ERFutils.concat_multirun(ERF[train],'model').mean(dim = 'model')\n",
    "    tas_all = tas_ds.mean(dim = ['model'])\n",
    "    #if 'ssp' in train:\n",
    "    #    tas_all = tas_all.sel(s = slice(165,250)).assign_coords(s = range(0,85))\n",
    "\n",
    "    tas_all = tas_all.rename({'s': 'year'})    \n",
    "    #tas_all = tas_all.sel(year = slice(ERF_all['year'].min(), ERF_all['year'].max()))\n",
    "\n",
    "    X1 = ERF_all.year.values\n",
    "    Y1 = ERF_all.ERF.values\n",
    "\n",
    "    X2 = tas_all.year.values\n",
    "    Y2 = tas_all.weighted(A).mean(dim = ['lat','lon']).tas.values\n",
    "\n",
    "    tau = 20\n",
    "    j = 4\n",
    "    \n",
    "    N_years = len(ERF_all['year']) - j\n",
    "    offsets = [i for i in range(0,-N_years,-1)]\n",
    "    domain = np.linspace(ERF_all.year.values[j], ERF_all.year.values[-1], num=N_years)\n",
    "\n",
    "    ERF_pred = [local_weighted_regression(x0, X1, Y1, tau) for x0 in domain]\n",
    "    tas_pred = [local_weighted_regression(x0, X2, Y2, tau) for x0 in domain]\n",
    "\n",
    "    input_matrix = diags(ERF_pred,offsets=offsets,shape=(N_years,N_years),format='csr')\n",
    "    G_glob = spsolve_triangular(input_matrix,tas_pred,lower=True)\n",
    "\n",
    "    array_mat = input_matrix.toarray()\n",
    "    cond_num = LA.cond(array_mat)\n",
    "    print(f'Cond: {cond_num}')\n",
    "\n",
    "    plt.plot(G_glob,label=j)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c5ee5f-d44f-4119-958f-0ac1e7d7b2cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_id = ['ssp585']#,'ssp245','ssp370','ssp585','1pctCO2']\n",
    "from numpy import linalg as LA\n",
    "from scipy.linalg import solve\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "A = ERFutils.A\n",
    "\n",
    "for train in train_id:\n",
    "    # Load ERF data\n",
    "    ERF = {}\n",
    "    ERF_path = f'../Outputs/RF_Outputs/ERF/ERF_{train}_all_ds.nc4'\n",
    "    \n",
    "    ERF_path_hist = f'../Outputs/RF_Outputs/ERF/ERF_historical_all_ds.nc4'\n",
    "    ERF_ssp = xr.open_dataset(ERF_path)\n",
    "    ERF_hist = xr.open_dataset(ERF_path_hist)\n",
    "\n",
    "    ERF_ds = xr.concat([ERF_hist,ERF_ssp.assign_coords(year = range(165,250))],dim = 'year')\n",
    "    \n",
    "    #ERF_ds = xr.open_dataset(ERF_path)\n",
    "    ERF[train] = ERFutils.ds_to_dict(ERF_ds)\n",
    "    \n",
    "    tas_path = f'../Outputs/RF_Outputs/tas/tas_CMIP_{train}_all_ds.nc4'\n",
    "    tas_ds = xr.open_dataset(tas_path)\n",
    "    \n",
    "    ERF_all = ERFutils.concat_multirun(ERF[train],'model').mean(dim = 'model')\n",
    "    tas_all = tas_ds.mean(dim = ['model'])\n",
    "    #if 'ssp' in train:\n",
    "    #    tas_all = tas_all.sel(s = slice(165,250)).assign_coords(s = range(0,85))\n",
    "\n",
    "    tas_all = tas_all.rename({'s': 'year'})    \n",
    "    #tas_all = tas_all.sel(year = slice(ERF_all['year'].min(), ERF_all['year'].max()))\n",
    "\n",
    "    X1 = ERF_all.year.values\n",
    "    Y1 = ERF_all.ERF.values\n",
    "\n",
    "    X2 = tas_all.year.values\n",
    "    Y2 = tas_all.weighted(A).mean(dim = ['lat','lon']).tas.values\n",
    "\n",
    "    #tau = 20\n",
    "    #j = 75\n",
    "    for tau in [20]:\n",
    "        for j in [165]:\n",
    "            N_years = len(ERF_all['year']) - j\n",
    "            offsets = [i for i in range(0,-N_years,-1)]\n",
    "            domain = np.linspace(ERF_all.year.values[j], ERF_all.year.values[-1], num=N_years)\n",
    "\n",
    "            ERF_pred = [local_weighted_regression(x0, X1, Y1, tau) for x0 in domain]\n",
    "            tas_pred = [local_weighted_regression(x0, X2, Y2, tau) for x0 in domain]\n",
    "\n",
    "            input_matrix = diags(ERF_pred,offsets=offsets,shape=(N_years,N_years),format='csr')\n",
    "            G_glob = spsolve_triangular(input_matrix,tas_pred,lower=True)\n",
    "\n",
    "            array_mat = input_matrix.toarray()\n",
    "            cond_num = LA.cond(array_mat)\n",
    "            print(f'Cond: {cond_num}')\n",
    "\n",
    "            plt.plot(G_glob,label=f'{tau}, {j}')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f2b9f6-88da-4e03-a05c-b8fc202a3adc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#plt.plot(G.weighted(A).mean(dim = ['lat','lon'])['G[tas]'])\n",
    "plt.plot(ERF_all.ERF.values)\n",
    "plt.plot(tas_all.weighted(A).mean(dim = ['lat','lon']).tas.values)\n",
    "plt.plot(ERF_pred)\n",
    "plt.plot(tas_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2150a2f5-ecba-4fc3-a0db-d2c897f348ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "    # Have to create the Green's functions locally, stack data array\n",
    "    stacked_response = tas_all.stack(allpoints=['lat','lon'])\n",
    "    N_latlong = len(stacked_response.tas.values[0])\n",
    "    stacked_tas = stacked_response.tas.values\n",
    "\n",
    "    # Convert to np arrays, xarray indexing is too slow\n",
    "    G_stacked = np.zeros((N_years,N_latlong))\n",
    "\n",
    "    # Calculate local Green's functions, matrix is LD by construction\n",
    "    for n in range(N_latlong):\n",
    "        if n % 10000 == 0:\n",
    "            print(n)\n",
    "        Y3 = stacked_tas[:,n]\n",
    "        stacked_response_local = [local_weighted_regression(x0, X2, Y3, tau) for x0 in domain]\n",
    "        G_stacked[:,n] = spsolve_triangular(input_matrix,stacked_response_local,lower=True)\n",
    "\n",
    "    # Get G into the correct format\n",
    "    G = xr.Dataset(coords={'lon': ('lon', tas_all.lon.values),\n",
    "                            'lat': ('lat', tas_all.lat.values),\n",
    "                            'year': ('year', range(N_years))})\n",
    "    G = G.stack(allpoints=['lat','lon'])\n",
    "    G['G[tas]'] = (('year','allpoints'),G_stacked)\n",
    "    G = G.unstack('allpoints')\n",
    "\n",
    "    G['year'] = G['year'] - G['year'][0]\n",
    "\n",
    "    G.to_netcdf(f'../Outputs/RF_Outputs/GFs/G_loess_{train}_ERF_mean_ds.nc4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gchp",
   "language": "python",
   "name": "gchp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
